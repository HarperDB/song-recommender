{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "49f05e95-60d4-46e8-96d0-8396c2c144bb",
   "metadata": {},
   "outputs": [],
   "source": [
    "# recommendation_trainer.py\n",
    "import csv\n",
    "import numpy as np\n",
    "import tensorflow as tf\n",
    "import tensorflow_recommenders as tfrs\n",
    "\n",
    "n_songs_in = 3\n",
    "\n",
    "base_dir = '/data/song-recommender'\n",
    "weights_dir = base_dir +'/{}-weights'\n",
    "index_model_dir = base_dir + '/model'\n",
    "tfjs_model_dir = base_dir + '/tfjs-model'\n",
    "\n",
    "# create a list of users and songs\n",
    "users_songs = {}\n",
    "with open(base_dir + '/users_songs.csv') as file:\n",
    "    reader = csv.reader(file)\n",
    "    next(reader)\n",
    "    for line in reader:\n",
    "        user = int(line[0])\n",
    "        song = int(line[1])\n",
    "        try:\n",
    "            users_songs[user].append(song)\n",
    "        except:\n",
    "            users_songs[user] = [song]\n",
    "\n",
    "user_idxs = {}\n",
    "with open(base_dir + '/user_idxs.csv') as file:\n",
    "    reader = csv.reader(file)\n",
    "    next(reader)\n",
    "    for line in reader:\n",
    "        user_idxs[int(line[1])] = line[0]\n",
    "\n",
    "song_idxs = {}\n",
    "with open(base_dir + '/song_idxs.csv') as file:\n",
    "    reader = csv.reader(file)\n",
    "    next(reader)\n",
    "    for line in reader:\n",
    "        song_idxs[int(line[1])] = line[0]\n",
    "\n",
    "n_users = len(user_idxs)\n",
    "n_songs = len(song_idxs)\n",
    "print('n_users', n_users)\n",
    "print('n_songs', n_songs)\n",
    "# create a dictionary of inputs and outputs\n",
    "dataset = {'songs': [], 'user': []}\n",
    "for user, songs in users_songs.items():\n",
    "    for _ in range(len(songs) * 5):\n",
    "        # randomly select n_songsns_in from the user's isbns\n",
    "        selected_songs = np.random.choice(songs, n_songs_in)\n",
    "        # add them to the inputs\n",
    "        dataset['songs'].append(selected_songs)\n",
    "        # add the user to the output\n",
    "        dataset['user'].append(user)\n",
    "        \n",
    "# create a permutation to randomly shuffle all of the above data\n",
    "# a permutation is created first so the same order can be applied\n",
    "# to the inputs and the outputs\n",
    "permutation = np.random.permutation(len(dataset['songs']))\n",
    "# apply the above permutation to the inputs and the outputs\n",
    "dataset = {\n",
    "    'songs': np.asarray(dataset['songs'])[permutation],\n",
    "    'user': np.asarray(dataset['user'])[permutation]\n",
    "}\n",
    "# convert the above dictionary to a TF Dataset\n",
    "dataset = tf.data.Dataset.from_tensor_slices(dataset)\n",
    "\n",
    "print('len_dataset', permutation.shape[0])\n",
    "# print an example of the data in the dataset\n",
    "for d in dataset.take(1):\n",
    "    print(d)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f133d523-9c50-4e51-a3b3-0f2ef67ab177",
   "metadata": {},
   "outputs": [],
   "source": [
    "# create the query and candidate models\n",
    "n_embedding_dimensions = 24\n",
    "\n",
    "## QUERY\n",
    "songs_in_in = tf.keras.Input(shape=(n_songs_in))\n",
    "songs_in_emb = tf.keras.layers.Embedding(n_songs+1, n_embedding_dimensions)(songs_in_in)\n",
    "songs_in_emb_avg = tf.keras.layers.AveragePooling1D(pool_size=3)(songs_in_emb)\n",
    "query = tf.keras.layers.Flatten()(songs_in_emb_avg)\n",
    "query_model = tf.keras.Model(inputs=songs_in_in, outputs=query)\n",
    "\n",
    "## CANDIDATE\n",
    "user_in = tf.keras.Input(shape=(1))\n",
    "user_emb = tf.keras.layers.Embedding(n_users+1, n_embedding_dimensions)(user_in)\n",
    "candidate = tf.keras.layers.Flatten()(user_emb)\n",
    "candidate_model = tf.keras.Model(inputs=user_in, outputs=candidate)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6f58527d-28cf-41d2-9431-d81c2da989cc",
   "metadata": {},
   "outputs": [],
   "source": [
    "# TFRS TASK SETUP\n",
    "candidates = dataset.batch(128).map(lambda x: candidate_model(x['user']))\n",
    "metrics = tfrs.metrics.FactorizedTopK(candidates=candidates)\n",
    "task = tfrs.tasks.Retrieval(metrics=metrics)\n",
    "\n",
    "\n",
    "## TFRS MODEL CLASS\n",
    "class Model(tfrs.Model):\n",
    "    def __init__(self, query_model, candidate_model):\n",
    "        super().__init__()\n",
    "        self._query_model = query_model\n",
    "        self._candidate_model = candidate_model\n",
    "        self._task = task\n",
    "\n",
    "    def compute_loss(self, features, training=False):\n",
    "        query_embedding = self._query_model(features['songs'])\n",
    "        candidate_embedding = self._candidate_model(features['user'])\n",
    "        return self._task(query_embedding, candidate_embedding)\n",
    "\n",
    "## COMPILE AND TRAIN MODEL\n",
    "model = Model(query_model, candidate_model)\n",
    "# load model weights - this is to resume training\n",
    "# model._query_model.load_weights(weights_dir.format('query'))\n",
    "# model._candidate_model.load_weights(weights_dir.format('candidate'))\n",
    "\n",
    "model.compile(optimizer=tf.keras.optimizers.Adagrad(learning_rate=0.1))\n",
    "model.fit(dataset.repeat().shuffle(300_000).batch(4096), steps_per_epoch=50, epochs=30, verbose=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8c142b6f-534e-418c-9e46-0aa03d5738ea",
   "metadata": {},
   "outputs": [],
   "source": [
    "model.fit(dataset.repeat().shuffle(300_000).batch(4096), steps_per_epoch=50, epochs=30, verbose=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d88d2b77-d1aa-4da0-a1ca-50c791c9d116",
   "metadata": {},
   "outputs": [],
   "source": [
    "# save the model weights\n",
    "model._query_model.save_weights(weights_dir.format('query'))\n",
    "model._candidate_model.save_weights(weights_dir.format('candidate'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "658b5204-b0d9-4299-8c76-4fcadbe9053a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# create the index model to lookup the best candidate match for a query\n",
    "index = tfrs.layers.factorized_top_k.BruteForce(model._query_model)\n",
    "index.index_from_dataset(\n",
    "    tf.data.Dataset.zip((\n",
    "      dataset.map(lambda x: x['user']).batch(100),\n",
    "      dataset.batch(100).map(lambda x: model._candidate_model(x['user']))\n",
    "    ))\n",
    ")\n",
    "for features in dataset.shuffle(2000).batch(1).take(1):\n",
    "    print('songs', features['songs'])\n",
    "    scores, users = index(features['songs'])\n",
    "    print('recommended users', users)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "74f118c0-e53d-4ef3-8035-0cf55dcaf49b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# save the index model\n",
    "index.save(index_model_dir)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d91cddbd-914c-472e-9da9-57a87a52c7f9",
   "metadata": {},
   "outputs": [],
   "source": [
    "## CONVERT TO TFJS MODEL\n",
    "import subprocess\n",
    "cmd = [\n",
    "    'tensorflowjs_converter',\n",
    "    '--input_format=tf_saved_model',\n",
    "    '--output_format=tfjs_graph_model',\n",
    "    index_model_dir,\n",
    "    tfjs_model_dir\n",
    "]\n",
    "subprocess.run(cmd)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
